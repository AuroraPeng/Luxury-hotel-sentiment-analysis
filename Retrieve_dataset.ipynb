{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c23b128b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import locale\n",
    "import os\n",
    "import pandas as pd\n",
    "import tweepy\n",
    "import re\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fa56cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_US.UTF-8'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locale.setlocale( locale.LC_ALL, 'en_US.UTF-8' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edbbd5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/aurorapeng/Documents/GitHub/Luxury-hotel-sentiment-analysis')\n",
    "path_to_driver_1 = '/Users/aurorapeng/Documents/GitHub/Luxury-hotel-sentiment-analysis/chromedriver'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa029471",
   "metadata": {},
   "source": [
    "# Scrape Tripadvisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ed82ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_tripadvisor_review(path_to_driver_1,link_to_scrape):\n",
    "    driver = webdriver.Chrome(executable_path=path_to_driver_1)\n",
    "\n",
    "    # %%%% Link\n",
    "    driver.get(link_to_scrape)\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, \"//span[@class='iypZC Mc _R b']\")))\n",
    "\n",
    "    total_n_reviews_int = driver.find_element(\"xpath\",\"//span[@class='iypZC Mc _R b']\").text\n",
    "\n",
    "    total_n_reviews_int = int(total_n_reviews_int)-220\n",
    "\n",
    "\n",
    "    # %%%% Scraping\n",
    "    reviews_dict = []\n",
    "    while True:\n",
    "        # waits for the reviews to be visible before grabbing their elements\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//div[@class='YibKl MC R2 Gi z Z BB pBbQr']\")))\n",
    "\n",
    "\n",
    "        reviews = driver.find_elements(\"xpath\",\"//div[@class='YibKl MC R2 Gi z Z BB pBbQr']\")\n",
    "\n",
    "        r=0\n",
    "        # for loop to scrape through reviews\n",
    "        for r in range(len(reviews)):\n",
    "            one_review                     = {}\n",
    "            one_review['scrapping_date']   = datetime.datetime.now()\n",
    "            try:                \n",
    "                soup                       = BeautifulSoup(reviews[r].get_attribute('innerHTML'))\n",
    "            except:\n",
    "                    # I got StaleElementReferenceException a lot here, so in order to solve this problem,\n",
    "                    # I just refresh the page, make sure the elements are there and reinitialize reviews.\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.XPATH, \"//div[@class='YibKl MC R2 Gi z Z BB pBbQr']\")))\n",
    "                reviews = driver.find_elements(\"xpath\",\"//div[@class='YibKl MC R2 Gi z Z BB pBbQr']\")\n",
    "                soup                       = BeautifulSoup(reviews[r].get_attribute('innerHTML'))\n",
    "\n",
    "\n",
    "            # pulls reviwerid and date from innerHTML soup\n",
    "            try:\n",
    "                one_review_id            = soup.find('div', attrs={'class':'cRVSd'}).text.split(' wrote a review ')[0].strip()\n",
    "                one_reviewer_date        = soup.find('div', attrs={'class':'cRVSd'}).text.split(' wrote a review ')[1].strip()\n",
    "            except:\n",
    "                one_review_id            = \"\"\n",
    "                one_reviewer_date        = \"\"\n",
    "            one_review['reviewer_name']  = one_review_id\n",
    "            one_review['review_date']    = one_reviewer_date\n",
    "\n",
    "            # pulls rating from innerHTML soup\n",
    "            try:\n",
    "                for headlines in soup.findAll('div',{'class':'Hlmiy F1'}):\n",
    "                    for p in headlines.find_all('span', recursive=False):\n",
    "                        ratings = int(p['class'][1].replace('bubble_','').strip())/10\n",
    "            except:\n",
    "                ratings            = \"\"\n",
    "            one_review['rating']      = ratings\n",
    "\n",
    "            # pulls review title from innerHTML soup\n",
    "            try:\n",
    "                one_review_title            = soup.find('div', attrs={'class':'KgQgP MC _S b S6 H5 _a'}).text.strip()\n",
    "            except:\n",
    "                one_review_title            = \"\"\n",
    "            one_review['review_title']  = one_review_title\n",
    "\n",
    "            # pulls review from innerHTML soup\n",
    "            try:\n",
    "                one_review_content            = soup.find('q', attrs={'class':'QewHA H4 _a'}).text.strip()\n",
    "            except:\n",
    "                one_review_title            = \"\"\n",
    "            one_review['review_content']  = one_review_content\n",
    "\n",
    "            # pulls date of stay from innerHTML soup\n",
    "            try:\n",
    "                date_of_stays            = soup.find('span', attrs={'class':'teHYY _R Me S4 H3'}).text.replace('Date of stay: ','').strip()\n",
    "            except:\n",
    "                date_of_stays            = \"\"\n",
    "            one_review['date_of_stays']  = date_of_stays\n",
    "\n",
    "            reviews_dict.append(one_review)\n",
    "\n",
    "        # Keeps clicking next page until all reviews are collected\n",
    "        #if len(reviews_dict) < total_n_reviews_int: The tricky thing is in the Tripadvisor, the ACTUAL review number is actually less than what they propaganed in their website, \n",
    "        # which always tell me StaleElementReferenceException, in order to solve this question I just got to the final page which is the 32rd page and count there are only 3 views left, \n",
    "        #which makes the actual total review only 3103 views, we can assume maybe there are 200 views that are not diclosed\n",
    "        if len(reviews_dict) < total_n_reviews_int:\n",
    "            # clicks for next page\n",
    "            try:\n",
    "                # waits for the next page button to be visible, then clicks\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.visibility_of_element_located((By.XPATH, \"//a[@class='ui_button nav next primary ']\")))\n",
    "                driver.find_element(\"xpath\",\"//a[@class='ui_button nav next primary ']\").click()\n",
    "            except:\n",
    "\n",
    "                # then clicks next page\n",
    "                driver.find_element(\"xpath\",\"//a[@class='ui_button nav next primary ']\").click()\n",
    "        # When all reviews are in the dictionary, the while(True) loop breaks\n",
    "        else:\n",
    "            break \n",
    "    driver.close()\n",
    "    return reviews_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b4385",
   "metadata": {},
   "source": [
    "## Scrape the Tier One Hotel: Waldorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d18bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_to_scrape = 'https://www.tripadvisor.in/Hotel_Review-g35805-d1516481-Reviews-Waldorf_Astoria_Chicago-Chicago_Illinois.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9091f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "waldorf_reviews = pd.DataFrame.from_dict(scrape_tripadvisor_review(path_to_driver_1,link_to_scrape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bf431e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'waldorf_reviews_tripadvisor.csv'\n",
    "waldorf_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bd9982",
   "metadata": {},
   "source": [
    "## Scrape the Tier Two Hotel: DoubleTree by Hilton Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e3c03cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/0fc5xvvd01g47wjlznw52ghm0000gn/T/ipykernel_90443/4290313188.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=path_to_driver_1)\n"
     ]
    }
   ],
   "source": [
    "link_to_scrape = 'https://www.tripadvisor.com/Hotel_Review-g35805-d1235890-Reviews-TheWit_Chicago_a_DoubleTree_by_Hilton_Hotel-Chicago_Illinois.html'\n",
    "doubletree_reviews = pd.DataFrame.from_dict(scrape_tripadvisor_review(path_to_driver_1,link_to_scrape))\n",
    "file_name = 'doubletree_reviews_tripadvisor.csv'\n",
    "doubletree_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de86930e",
   "metadata": {},
   "source": [
    "## Scrape the Tier Three Hotel : Hilton Garden Inn Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "846ff629",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/0fc5xvvd01g47wjlznw52ghm0000gn/T/ipykernel_90443/4290313188.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=path_to_driver_1)\n"
     ]
    }
   ],
   "source": [
    "link_to_scrape = 'https://www.tripadvisor.com/Hotel_Review-g35805-d111487-Reviews-Hilton_Garden_Inn_Chicago_Downtown_Magnificent_Mile-Chicago_Illinois.html'\n",
    "hiltongarden_reviews = pd.DataFrame.from_dict(scrape_tripadvisor_review(path_to_driver_1,link_to_scrape))\n",
    "file_name = 'hiltongarden_reviews_tripadvisor.csv'\n",
    "hiltongarden_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fab1c",
   "metadata": {},
   "source": [
    "# Scrape Expedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "755b16a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_up_driver(link_to_scrape):\n",
    "    driver = webdriver.Chrome(executable_path=path_to_driver_1)\n",
    "\n",
    "    # %%%% Link\n",
    "    driver.get(link_to_scrape)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5bcf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_up_expedia_first(driver):\n",
    "\n",
    "    WebDriverWait(driver, 3).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//button[@data-stid='reviews-link']\")))\n",
    "\n",
    "    driver.find_element(\"xpath\",\"//button[@data-stid='reviews-link']\").click()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "be23cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expedia_review_scrape(driver):\n",
    "    \n",
    "    WebDriverWait(driver, 3).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//button[@class='uitk-link uitk-spacing uitk-spacing-padding-blockstart-two uitk-link-align-left uitk-link-layout-default uitk-link-medium']\")))\n",
    "\n",
    "    driver.find_element(\"xpath\",\"//button[@class='uitk-link uitk-spacing uitk-spacing-padding-blockstart-two uitk-link-align-left uitk-link-layout-default uitk-link-medium']\").click()\n",
    "\n",
    "    WebDriverWait(driver, 10).until(\n",
    "            EC.visibility_of_element_located((By.XPATH, \"//div[@class='uitk-text uitk-text-spacing-one uitk-type-300 uitk-text-default-theme']\")))\n",
    "\n",
    "    total_n_reviews_raw = driver.find_element(\"xpath\",\"//div[@class='uitk-text uitk-text-spacing-one uitk-type-300 uitk-text-default-theme']\").text\n",
    "    total_n_reviews_number = total_n_reviews_raw.strip(' verified reviews')\n",
    "    total_n_reviews_int = locale.atoi(total_n_reviews_raw.strip(' verified reviews'))\n",
    "    click_times = total_n_reviews_int//10\n",
    "    for r in range(click_times):\n",
    "        # clicks for next page\n",
    "        try:\n",
    "            # waits for the next page button to be visible, then clicks\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//div[@class='uitk-spacing uitk-type-center uitk-spacing-margin-block-three']\")))\n",
    "            driver.find_element(\"xpath\",\"//div[@class='uitk-spacing uitk-type-center uitk-spacing-margin-block-three']\").click()\n",
    "\n",
    "        except:\n",
    "     # waits for the next page button to be visible, then clicks\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//div[@class='uitk-spacing uitk-type-center uitk-spacing-margin-block-three']\")))\n",
    "            # then clicks next page\n",
    "            driver.find_element(\"xpath\",\"//div[@class='uitk-spacing uitk-type-center uitk-spacing-margin-block-three']\").click()\n",
    "\n",
    "    reviews_dict = []\n",
    "    WebDriverWait(driver, 3).until(\n",
    "        EC.visibility_of_element_located((By.XPATH, \"//div[@class='uitk-card-content-section uitk-card-content-section-border-block-end uitk-card-content-section-padded']\")))\n",
    "\n",
    "    reviews = driver.find_elements(By.XPATH, \"//div[@class='uitk-card-content-section uitk-card-content-section-border-block-end uitk-card-content-section-padded']\")\n",
    "    r=0\n",
    "    # for loop to scrape through reviews\n",
    "    for r in range(len(reviews)):\n",
    "        one_review                     = {}\n",
    "        one_review['scrapping_date']   = datetime.datetime.now()\n",
    "        try:                \n",
    "            soup                       = BeautifulSoup(reviews[r].get_attribute('innerHTML'))\n",
    "        except:\n",
    "                # I got StaleElementReferenceException a lot here, so in order to solve this problem,\n",
    "                # I just refresh the page, make sure the elements are there and reinitialize reviews.\n",
    "            WebDriverWait(driver, 3).until(\n",
    "                EC.visibility_of_element_located((By.XPATH, \"//article[@itemprop='review']\")))\n",
    "            reviews = driver.find_elements(\"xpath\",\"//article[@itemprop='review']\")\n",
    "            soup                       = BeautifulSoup(reviews[r].get_attribute('innerHTML'))\n",
    "\n",
    "\n",
    "        # pulls reviwer rating from innerHTML soup\n",
    "        try:\n",
    "            one_review_rating           = soup.find('span', attrs={'itemprop':'ratingValue'}).text.strip()\n",
    "        except:\n",
    "            one_review_rating           = \"\"\n",
    "        one_review['review_rating']  = one_review_rating\n",
    "\n",
    "        # pulls reviewer name from innerHTML soup\n",
    "        try:\n",
    "            one_reviewer_name           = soup.find('h5', attrs={'class':'uitk-heading uitk-heading-7'}).text.strip()\n",
    "        except:\n",
    "            one_reviewer_name            = \"\"\n",
    "        one_review['reviewer_name']      = one_reviewer_name\n",
    "\n",
    "        # pulls review date from innerHTML soup\n",
    "        try:\n",
    "            one_reviewer_date           = soup.find('span', attrs={'itemprop':'datePublished'}).text.strip()\n",
    "        except:\n",
    "            one_reviewer_date            = \"\"\n",
    "        one_review['review_date']  = one_reviewer_date\n",
    "\n",
    "        # pulls review title from innerHTML soup\n",
    "        try:\n",
    "            one_review_content_title            = soup.find('h5', attrs={'class':'uitk-heading uitk-heading-6'}).text.strip()\n",
    "        except:\n",
    "            one_review_content_title            = \"\"\n",
    "        one_review['review_title']  = one_review_content_title\n",
    "\n",
    "        # pulls review content from innerHTML soup\n",
    "        try:\n",
    "            one_review_content            = soup.find('span', attrs={'itemprop':'description'}).text.strip()\n",
    "        except:\n",
    "            one_review_content            = \"\"\n",
    "        one_review['review_content']  = one_review_content\n",
    "\n",
    "        reviews_dict.append(one_review)\n",
    "    driver.close()\n",
    "    return reviews_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8900bb88",
   "metadata": {},
   "source": [
    "## Scrape the Tier One Hotel: Waldorf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc9f6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_to_scrape = 'https://www.expedia.com/Chicago-Hotels-Waldorf-Astoria-Chicago.h2717582.Hotel-Information?chkin=2022-11-17&chkout=2022-11-18&destType=MARKET&destination=Chicago%2C%20Illinois%2C%20United%20States%20of%20America&neighborhoodId=553248635976470100&pwa_ts=1667488480957&referrerUrl=aHR0cHM6Ly93d3cuZXhwZWRpYS5jb20vSG90ZWwtU2VhcmNo&regionId=829&rfrr=HSR&rm1=a2&selected=2717582&selectedRatePlan=222049559&selectedRoomType=201371071&sort=RECOMMENDED&top_cur=USD&top_dp=548&useRewards=false&userIntent=&x_pwa=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c628d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/0fc5xvvd01g47wjlznw52ghm0000gn/T/ipykernel_90443/3466519808.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=path_to_driver_1)\n"
     ]
    }
   ],
   "source": [
    "driver = open_up_driver(link_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bc19d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refresh, do the rest of the scraping\n",
    "reviews_dict = expedia_review_scrape(driver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "850d860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%% To excel!\n",
    "expedia_waldorf_reviews = pd.DataFrame.from_dict(reviews_dict)\n",
    "file_name = 'expedia_waldorf_reviews.csv'\n",
    "expedia_waldorf_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140bd8a3",
   "metadata": {},
   "source": [
    "## Scrape the Tier Two Hotel: DoubleTree by Hilton Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3ffd9fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_to_scrape = 'https://www.expedia.com/Chicago-Hotels-DoubleTree-By-Hilton-Chicago-Magnificent-Mile.h21152.Hotel-Information?chkin=2022-11-17&chkout=2022-11-18&x_pwa=1&rfrr=HSR&pwa_ts=1667529187230&referrerUrl=aHR0cHM6Ly93d3cuZXhwZWRpYS5jb20vSG90ZWwtU2VhcmNo&useRewards=false&rm1=a2&destination=300+E+Ohio+St%2C+Chicago%2C+IL+60611%2C+USA&destType=ADDRESS&neighborhoodId=6130109&trackingData=AAAAEAB-BIgTf5G1NhzCaLgJTaWrYd9NlGvRQ6QytNZWZVX7nmMtD6_KrooBdgUjqDsyUC_hysxNoRWZpsOmqYpqH1pwDj14DFR6cWZg4sPDuAC0igupTFMrGOxew6nR7PqLQshXFahWGXVnbbJpTv6RrxYVpZWZXOcuUA2KFDxyTQG84MAXyQ9eON-eCjv8UbZ8nM3pmBp4B9Jg_2QITLSbF_eEGfMkLm50IP9VbbW7zOlXVVU6AkQrvfUqinvwKME6dYYt3uhBs_nnAL9zcyXSs76Qp57y9UKQ-xtQjtaknTzabpIQlz6cTOGyWiP7qcJ7IgdshQWoaw89gVA1XdDcJQntF4sb0UPN_UzjO9bc1ZUMb8qCYRQMUQ1lIIK3byD0WkTe8jochuUA2V6bceVlaBm5SQglFd1zQ420ufFlpMchPVRjLzvwYsn5a8J-rlXQ91C5VAwhrFnRxieT2tXxS-WtRqPULCVPDU4dA6AFZfRp_ALCBdy4pCnZr-H42uFoXeoxePunRG7NFKBlJueLsihC_CMrBngkJ3L2zLOUQnPAaoRmlDPpeeg8tIA2zI1Jnq9pYQMeANcUH1UFwoNk_34jnc1HtFhMP0Gsq-LVjB9uPq3GrtHKMzJjMTuAsfQXzgrn3-JsJqeYmmXGNC8FcZs6dsoImdoERDrwYlPrSAaO7I5A1osDZ1SqY_fsYLTyv7htcddemx7bVOcwcp3kTH2PMeWXtw72_1NI_FSEBRsfGNMUzNIN2qQDaVYvTmEw721vDXmeQFrUwtF4KYq0wULig249sELmlh0UAURTkIRnyVmo2vogzaRbJfa3a4XC1SfUssfAEYEJR2oNpl3sNg8314YxnMLVblQOC7Z13bssjRQTAhhCv6C1uByme3a8kszfjjmf_bH9ng57FfBNyktHq5ikYJwm5HTehZ5n8JCaasfUmMBOncMVWv4h5dwdJQNza_-1QzeFl3OdoyRBvZj7KUXEIi0XqSj51ILEss0XVVba4jfuUw79fFGz6VtPHxG9qMVgxUX-kXreKonTGRGzeD56jC0_URSjkSJL-ccCYlN8r2wR_iYRV4-_DwHpINneDEjs8khKpOtHX34I97DwyfpuPXc12-mAGY73_erg&rank=1&testVersionOverride=Buttercup%2C44204.0.0%2C44203.0.0%2C43549.129874.3%2C43550.132977.0%2C31936.102311.0%2C33775.98848.1%2C38414.114301.0%2C39483.0.0%2C38427.115718.1%2C42444.0.0%2C42589.0.0%2C42876.124673.0%2C42973.0.0%2C42974.0.0%2C42975.0.0%2C42976.0.0%2C42802.125960.1%2C33739.99567.0%2C37898.109354.0%2C37930.0.0%2C37949.0.0%2C37354.113955.1%2C43435.128144.0%2C44597.132747.1%2C44701.0.0&slots=&position=1&beaconIssued=2022-11-04T02%3A33%3A06&sort=RECOMMENDED&top_dp=152&top_cur=USD&userIntent=&selectedRoomType=272309&selectedRatePlan=252035191'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "023ef68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/0fc5xvvd01g47wjlznw52ghm0000gn/T/ipykernel_90443/3466519808.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=path_to_driver_1)\n"
     ]
    }
   ],
   "source": [
    "driver = open_up_driver(link_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b69d516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refresh, do the rest of the scraping\n",
    "reviews_dict = expedia_review_scrape(driver)\n",
    "expedia_doubletree_reviews = pd.DataFrame.from_dict(reviews_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "29035dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%% To excel!\n",
    "file_name = 'expedia_doubletree_reviews.csv'\n",
    "expedia_doubletree_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33c2f93",
   "metadata": {},
   "source": [
    "## Scrape the Tier Three Hotel : Hilton Garden Inn Chicago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09ce94b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4l/0fc5xvvd01g47wjlznw52ghm0000gn/T/ipykernel_90443/3466519808.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(executable_path=path_to_driver_1)\n"
     ]
    }
   ],
   "source": [
    "link_to_scrape = 'https://www.expedia.com/Chicago-Hotels-Hilton-Garden-Inn-Chicago-Downtown-Riverwalk.h11501235.Hotel-Information?chkin=2022-11-17&chkout=2022-11-18&x_pwa=1&rfrr=HSR&pwa_ts=1667529399393&referrerUrl=aHR0cHM6Ly93d3cuZXhwZWRpYS5jb20vSG90ZWwtU2VhcmNo&useRewards=false&rm1=a2&destination=300+E+Ohio+St%2C+Chicago%2C+IL+60611%2C+USA&destType=ADDRESS&neighborhoodId=651190586167894016&hotelName=hilton+garden+inn&sort=RECOMMENDED&top_dp=183&top_cur=USD&userIntent=&selectedRoomType=201165573&selectedRatePlan=278102663'\n",
    "driver = open_up_driver(link_to_scrape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f388f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refresh, do the rest of the scraping\n",
    "reviews_dict = expedia_review_scrape(driver)\n",
    "expedia_hiltongarden_reviews = pd.DataFrame.from_dict(reviews_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9090b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%%% To excel!\n",
    "file_name = 'expedia_hiltongarden_reviews.csv'\n",
    "expedia_hiltongarden_reviews.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76206170",
   "metadata": {},
   "source": [
    "## scrape tweeter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2946578",
   "metadata": {},
   "source": [
    "The aim for this dataset is to scraping the twitter's raw comment for the brand Caraway. We are sure that for the Caraway brand as a cookware brand they are also curious about how they are being talked about online."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08e3493",
   "metadata": {},
   "source": [
    "## 1.Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5255d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input the twitter Dev\n",
    "consumer_key = \"h6Krb4Ho5LpGVIdYsCIbDjFXI\"\n",
    "consumer_secret = \"suroSy8MRGuevHO9pStnKdZm4WJMTTnf7NXdr85ueEgLLESRis\"\n",
    "access_token = \"1471011582377447425-69XGviuJUqtGJ9TbTzBLEjS2TM5jWc\"\n",
    "access_token_secret = \"KgqqBL42JaVFhnGag3UuJgJxtW6HSQAikYx4v0Yhr7sjp\"\n",
    "\n",
    "# Send authorization to Twitter API\n",
    "auth = tweepy.OAuth1UserHandler(\n",
    "  consumer_key, \n",
    "  consumer_secret, \n",
    "  access_token, \n",
    "  access_token_secret\n",
    ")\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed55bc78",
   "metadata": {},
   "source": [
    "## 2.Scrape Waldorf Astoria tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e23ba349",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'Waldorf Astoria'\n",
    "count = 100\n",
    "try:\n",
    " # Creation of query method using parameters\n",
    " tweets = tweepy.Cursor(api.search_tweets,q=text_query).items(count)\n",
    " \n",
    " # Pulling information from tweets iterable object\n",
    " tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    " \n",
    " # Creation of dataframe from tweets list\n",
    " # Add or remove columns as you remove tweet information\n",
    " tweets_df = pd.DataFrame(tweets_list)\n",
    " \n",
    "except BaseException as e:\n",
    "    print('failed on_status,',str(e))\n",
    "    time.sleep(3)\n",
    "\n",
    "file_name = 'Waldorf_tweets.csv'\n",
    "tweets_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2fdcc6",
   "metadata": {},
   "source": [
    "## 3. Scrape DoubleTree by Hilton Chicago tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "131995a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'DoubleTree by Hilton Chicago'\n",
    "count = 100\n",
    "try:\n",
    " # Creation of query method using parameters\n",
    " tweets = tweepy.Cursor(api.search_tweets,q=text_query).items(count)\n",
    " \n",
    " # Pulling information from tweets iterable object\n",
    " tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    " \n",
    " # Creation of dataframe from tweets list\n",
    " # Add or remove columns as you remove tweet information\n",
    " tweets_df = pd.DataFrame(tweets_list)\n",
    " \n",
    "except BaseException as e:\n",
    "    print('failed on_status,',str(e))\n",
    "    time.sleep(3)\n",
    "\n",
    "file_name = 'DoubleTree_by_Hilton_Chicago_tweets.csv'\n",
    "tweets_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c203db34",
   "metadata": {},
   "source": [
    "## 4. Scrape Hilton Garden Inn tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09967430",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_query = 'Hilton_Garden_Inn'\n",
    "count = 100\n",
    "try:\n",
    " # Creation of query method using parameters\n",
    " tweets = tweepy.Cursor(api.search_tweets,q=text_query).items(count)\n",
    " \n",
    " # Pulling information from tweets iterable object\n",
    " tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    " \n",
    " # Creation of dataframe from tweets list\n",
    " # Add or remove columns as you remove tweet information\n",
    " tweets_df = pd.DataFrame(tweets_list)\n",
    " \n",
    "except BaseException as e:\n",
    "    print('failed on_status,',str(e))\n",
    "    time.sleep(3)\n",
    "\n",
    "file_name = 'Hilton_Garden_Inn_tweets.csv'\n",
    "tweets_df.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbef6740",
   "metadata": {},
   "source": [
    "# Data Wrangling and Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151ed0a",
   "metadata": {},
   "source": [
    "To combine data from two travel website sources into a master table, some preliminary data cleaning were required. For consistency, I \n",
    "(1) renamed some variable names, \n",
    "(2) limited review ratings to one digit (with no decimal places or word descriptions like \"Excellent\"), \n",
    "(3) added a column indicating the data source (i.e. Tripadvisor or Expedia), \n",
    "(4) added a column indicating the hotel name (i.e. Waldorf, DoubleTree, or Hilton Garden Inn), \n",
    "(5) added a column indicating the time period (i.e. pre-Covid, during-Covid, or post-Covid), and \n",
    "(6) rescaled rating from a 0-5 scale to a 0-1 scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Waldorf\n",
    "# Tripadvisor\n",
    "waldorf_reviews['hotel_name'] = 'Waldorf'\n",
    "waldorf_reviews['source_name'] = 'Tripadvisor'\n",
    "# Expedia\n",
    "expedia_waldorf_reviews['hotel_name'] = 'Waldorf'\n",
    "expedia_waldorf_reviews['source_name'] = 'Expedia'\n",
    "expedia_waldorf_reviews = expedia_waldorf_reviews.rename(columns={'review_rating': 'rating'})\n",
    "expedia_waldorf_reviews['rating'] = expedia_waldorf_reviews['rating'].str[0]\n",
    "expedia_waldorf_reviews['rating'].astype(float)\n",
    "\n",
    "# DoubleTree by Hilton Chicago\n",
    "# Tripadvisor\n",
    "doubletree_reviews['hotel_name'] = 'DoubleTree'\n",
    "doubletree_reviews['source_name'] = 'Tripadvisor'\n",
    "# Expedia\n",
    "expedia_doubletree_reviews['hotel_name'] = 'DoubleTree'\n",
    "expedia_doubletree_reviews['source_name'] = 'Expedia'\n",
    "expedia_doubletree_reviews = expedia_doubletree_reviews.rename(columns={'review_rating': 'rating'})\n",
    "expedia_doubletree_reviews['rating'] = expedia_doubletree_reviews['rating'].str[0]\n",
    "expedia_doubletree_reviews['rating'].astype(float)\n",
    "\n",
    "# Hilton Garden Inn Chicago\n",
    "# Tripadvisor\n",
    "hiltongarden_reviews['hotel_name'] = 'Hilton Garden Inn'\n",
    "hiltongarden_reviews['source_name'] = 'Tripadvisor'\n",
    "\n",
    "# Expedia\n",
    "expedia_hiltongarden_reviews['hotel_name'] = 'Hilton Garden Inn'\n",
    "expedia_hiltongarden_reviews['source_name'] = 'Expedia'\n",
    "expedia_hiltongarden_reviews = expedia_hiltongarden_reviews.rename(columns={'review_rating': 'rating'})\n",
    "expedia_hiltongarden_reviews['rating'] = expedia_hiltongarden_reviews['rating'].str[0]\n",
    "expedia_hiltongarden_reviews['rating'].astype(float)\n",
    "\n",
    "# Combine all datasets and export\n",
    "master_table = pd.concat([waldorf_reviews, \n",
    "                          expedia_waldorf_reviews, \n",
    "                          doubletree_reviews, \n",
    "                          expedia_doubletree_reviews, \n",
    "                          hiltongarden_reviews, \n",
    "                          expedia_hiltongarden_reviews])\n",
    "\n",
    "# Define the following periods:\n",
    "# post-Covid period as Year > 2020, during-Covid as Year = 2020, pre-Covid as Year < 2020\n",
    "period = []\n",
    "for i in master_table['review_date']:\n",
    "    if (i.endswith('2020') == True):\n",
    "        x = 'during-Covid'    \n",
    "        period.append(x)\n",
    "    elif (i.endswith(('2021', '2022'))):     \n",
    "        x = 'post-Covid'\n",
    "        period.append(x)\n",
    "    else:    \n",
    "        x = 'pre-Covid'\n",
    "        period.append(x)\n",
    "master_table['period'] = period\n",
    "\n",
    "# scale rating to 0-1\n",
    "master_table['rating_rescale'] = master_table['rating'].astype(int)/5\n",
    "master_table['review_content'].astype(str)\n",
    "\n",
    "\n",
    "master_table.to_csv(r'clean_data/master_table.csv', header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
